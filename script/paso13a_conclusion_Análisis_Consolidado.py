"""
================================================================================
TELECOMX - PASO 13A: AN√ÅLISIS CONSOLIDADO DE FACTORES DE CHURN - VERSION 2
================================================================================
Descripci√≥n: Consolidaci√≥n y an√°lisis de resultados de evaluaci√≥n de modelos
             e importancia de variables para identificar factores cr√≠ticos
             de churn y su nivel de accionabilidad para el negocio.

Versi√≥n 2: Mejoras en visualizaciones (colores, tama√±os, legibilidad)

Inputs: 
- Resultados del Paso 11 (Evaluaci√≥n de modelos)
- Resultados del Paso 12 (Importancia de variables)
- Dataset base de entrenamiento

Outputs:
- Factores cr√≠ticos de churn identificados y categorizados
- An√°lisis de accionabilidad por variable
- Insights de negocio por categor√≠a
- JSON con datos consolidados para scripts posteriores

Autor: Sistema de An√°lisis Predictivo TelecomX
Fecha: 2025
================================================================================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import logging
import os
import json
import pickle
from datetime import datetime
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

def setup_logging():
    """Configurar sistema de logging"""
    os.makedirs('logs', exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/paso13a_analisis_consolidado_v2.log', mode='a', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def create_directories():
    """Crear directorios necesarios"""
    directories = ['excel', 'informes', 'graficos', 'logs', 'datos']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        logging.info(f"Carpeta verificada/creada: {directory}")

def find_latest_file(directory, pattern):
    """Encontrar el archivo m√°s reciente que coincida con el patr√≥n"""
    files = list(Path(directory).glob(pattern))
    if not files:
        raise FileNotFoundError(f"No se encontraron archivos con patr√≥n {pattern} en {directory}")
    latest_file = max(files, key=os.path.getctime)
    return str(latest_file)

def load_previous_results():
    """Cargar resultados de pasos anteriores (Paso 11 y 12)"""
    try:
        logging.info("Cargando resultados de pasos anteriores...")
        
        results = {}
        
        # 1. Cargar resultados del Paso 11 (Evaluaci√≥n de modelos)
        try:
            modelo_recomendado_file = find_latest_file('informes', 'paso11_modelo_recomendado_*.json')
            
            # Cargar recomendaci√≥n de modelo
            with open(modelo_recomendado_file, 'r', encoding='utf-8') as f:
                model_recommendation = json.load(f)
            
            results['paso11'] = {
                'model_recommendation': model_recommendation,
                'best_model': model_recommendation['best_model']['name'],
                'model_score': model_recommendation['best_model']['score'],
                'production_ready': model_recommendation['ready_for_production']
            }
            
            logging.info(f"Paso 11 cargado - Mejor modelo: {model_recommendation['best_model']['name']}")
            
        except FileNotFoundError as e:
            logging.error(f"No se pudo cargar Paso 11: {str(e)}")
            raise ValueError("Se requieren resultados del Paso 11 para continuar")
        
        # 2. Cargar resultados del Paso 12 (Importancia de variables)
        try:
            importance_excel_file = find_latest_file('excel', 'paso12_analisis_importancia_variables_*.xlsx')
            
            # Cargar datos de importancia desde Excel
            importance_data = load_importance_data_from_excel(importance_excel_file)
            
            results['paso12'] = {
                'excel_file': importance_excel_file,
                'data': importance_data
            }
            
            logging.info(f"Paso 12 cargado - Variables analizadas: {len(importance_data['comparison'])}")
            
        except FileNotFoundError as e:
            logging.error(f"No se pudo cargar Paso 12: {str(e)}")
            raise ValueError("Se requieren resultados del Paso 12 para continuar")
        
        # 3. Cargar dataset base para an√°lisis adicional
        try:
            train_file = find_latest_file('datos', 'telecomx_train_dataset_*.csv')
            
            # Probar diferentes encodings
            encodings = ['utf-8-sig', 'utf-8', 'cp1252', 'latin-1']
            df_base = None
            
            for encoding in encodings:
                try:
                    df_base = pd.read_csv(train_file, encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if df_base is not None:
                results['dataset'] = {
                    'data': df_base,
                    'file': train_file,
                    'size': len(df_base),
                    'churn_rate': df_base['Abandono_Cliente'].mean(),
                    'features': df_base.drop(columns=['Abandono_Cliente']).columns.tolist()
                }
                logging.info(f"Dataset base cargado: {len(df_base):,} registros, {df_base['Abandono_Cliente'].mean():.1%} churn")
            else:
                raise ValueError("No se pudo cargar el dataset base")
            
        except Exception as e:
            logging.warning(f"No se pudo cargar dataset base: {str(e)}")
            results['dataset'] = None
        
        return results
        
    except Exception as e:
        logging.error(f"Error cargando resultados anteriores: {str(e)}")
        raise

def load_importance_data_from_excel(excel_file):
    """Cargar datos de importancia desde el Excel del Paso 12"""
    try:
        # Leer hojas del Excel
        random_forest_df = pd.read_excel(excel_file, sheet_name='Random Forest')
        logistic_reg_df = pd.read_excel(excel_file, sheet_name='Regresi√≥n Log√≠stica')
        comparison_df = pd.read_excel(excel_file, sheet_name='Comparaci√≥n Modelos')
        
        return {
            'random_forest': random_forest_df,
            'logistic_regression': logistic_reg_df,
            'comparison': comparison_df
        }
        
    except Exception as e:
        logging.error(f"Error cargando datos de importancia: {str(e)}")
        raise

def identify_critical_churn_factors(previous_results):
    """Identificar y analizar factores cr√≠ticos de churn"""
    logging.info("Identificando factores cr√≠ticos de churn...")
    
    try:
        # Obtener datos de importancia
        importance_data = previous_results['paso12']['data']
        model_info = previous_results['paso11']
        dataset_info = previous_results['dataset']
        
        # Variables m√°s importantes por consenso (top 10)
        top_variables = importance_data['comparison'].head(10).copy()
        
        # Obtener informaci√≥n adicional de regresi√≥n log√≠stica para cada variable
        lr_data = importance_data['logistic_regression']
        
        critical_factors = []
        
        for _, row in top_variables.iterrows():
            variable = row['Variable']
            rf_importance = row['RF Importancia (%)']
            lr_importance = row['LR Importancia (%)']
            avg_importance = row['Importancia Promedio']
            
            # Buscar informaci√≥n de regresi√≥n log√≠stica
            lr_info = lr_data[lr_data['Variable'] == variable]
            
            factor_info = {
                'variable': variable,
                'rf_importance': rf_importance,
                'lr_importance': lr_importance,
                'avg_importance': avg_importance,
                'ranking': len(critical_factors) + 1,
                'coefficient': lr_info.iloc[0]['Coeficiente'] if len(lr_info) > 0 else 0,
                'odds_ratio': lr_info.iloc[0]['Odds Ratio'] if len(lr_info) > 0 else 1,
                'direction': lr_info.iloc[0]['Direcci√≥n'] if len(lr_info) > 0 else 'Neutral',
                'category': categorize_variable(variable),
                'business_impact': get_business_interpretation(variable),
                'actionability_score': get_actionability_score(variable),
                'implementation_complexity': get_implementation_complexity(variable),
                'time_to_impact': get_time_to_impact(variable)
            }
            
            critical_factors.append(factor_info)
        
        logging.info(f"Identificados {len(critical_factors)} factores cr√≠ticos")
        return critical_factors
        
    except Exception as e:
        logging.error(f"Error identificando factores cr√≠ticos: {str(e)}")
        raise

def categorize_variable(variable):
    """Categorizar variable por √°rea de negocio"""
    
    # Diccionario de categorizaci√≥n
    categories = {
        'Contractuales': ['Tipo_Contrato', 'Meses_Antig√ºedad', 'Facturacion_Digital'],
        'Financieras': ['Cargos_Mensuales', 'Cargos_Totales'],
        'Servicios_Internet': ['Servicio_Internet'],
        'Servicios_Adicionales': ['Servicio_Online_Security', 'Servicio_Online_Backup', 
                                 'Servicio_Device_Protection', 'Servicio_Tech_Support',
                                 'Servicio_Streaming_TV', 'Servicio_Streaming_Movies'],
        'Demogr√°ficas': ['Edad', 'Genero', 'Senior_Citizen'],
        'Tecnol√≥gicas': ['Metodo_Pago'],
        'Comunicaciones': ['Telefono_Multiples_Lineas']
    }
    
    for category, variables in categories.items():
        if variable in variables:
            return category
    
    # Categorizaci√≥n por patrones si no se encuentra exacta
    if 'Servicio' in variable:
        return 'Servicios_Adicionales'
    elif 'Cargos' in variable or 'Precio' in variable:
        return 'Financieras'
    elif 'Contrato' in variable or 'Meses' in variable:
        return 'Contractuales'
    else:
        return 'Otras'

def get_business_interpretation(variable):
    """Obtener interpretaci√≥n de negocio detallada"""
    
    interpretations = {
        'Meses_Antig√ºedad': 'Los clientes nuevos (< 12 meses) tienen 3-5x mayor riesgo de churn. La retenci√≥n temprana es cr√≠tica para el √©xito a largo plazo.',
        'Tipo_Contrato': 'Los contratos mensuales presentan 70% m√°s churn que anuales. Migrar a contratos largos es una prioridad estrat√©gica.',
        'Cargos_Mensuales': 'Existe correlaci√≥n directa entre precio alto y propensi√≥n al churn. Segmentaci√≥n de precios es clave.',
        'Cargos_Totales': 'Indica profundidad de relaci√≥n. Clientes con mayor spend hist√≥rico tienden a ser m√°s leales.',
        'Servicio_Internet': 'Fibra √≥ptica genera mayor satisfacci√≥n que DSL. Calidad de conexi√≥n es diferenciador competitivo.',
        'Servicio_Online_Security': 'Servicios de seguridad act√∫an como "anclas" que aumentan switching costs y lealtad.',
        'Servicio_Tech_Support': 'Soporte t√©cnico de calidad es predictor fuerte de retenci√≥n. Investment en support ROI positivo.',
        'Facturacion_Digital': 'Facturaci√≥n digital correlaciona con perfiles m√°s tech-savvy y menor churn.',
        'Metodo_Pago': 'D√©bito autom√°tico indica mayor compromiso que pagos manuales.',
        'Senior_Citizen': 'Ciudadanos senior tienen patrones de churn espec√≠ficos relacionados con simplicidad y servicio personal.'
    }
    
    return interpretations.get(variable, f'Variable {variable} con impacto significativo en predicci√≥n de churn. Requiere an√°lisis espec√≠fico.')

def get_actionability_score(variable):
    """Evaluar capacidad de intervenci√≥n sobre una variable (1-10 scale)"""
    
    intervention_scores = {
        # Mapeo con nombres EXACTOS del dataset
        'Meses_Cliente': 3,          # No podemos intervenir - es hist√≥rico
        'Tipo_Contrato_encoded': 9,   # Podemos intervenir f√°cilmente - cambiar t√©rminos
        'Cargo_Total': 2,            # No podemos intervenir - es hist√≥rico
        'Servicio_Internet_Fibra Optica': 6,  # Podemos intervenir con esfuerzo - infraestructura
        'Soporte_Tecnico_No': 9,     # Podemos intervenir f√°cilmente - mejorar soporte
        'Seguridad_Online_No': 8,    # Podemos intervenir f√°cilmente - promocionar servicio
        'Servicio_Internet_No': 6,   # Podemos intervenir con esfuerzo
        'Metodo_Pago_Cheque Electronico': 8,  # Podemos intervenir f√°cilmente - cambiar m√©todo
        
        # Patrones alternativos comunes
        'Tipo_Contrato': 9,
        'Cargos_Mensuales': 8,
        'Cargos_Totales': 2,
        'Meses_Antig√ºedad': 3,
        'Servicio_Tech_Support': 9,
        'Servicio_Online_Security': 8,
        'Facturacion_Digital': 8,
        'Metodo_Pago': 8,
        'Servicio_Internet': 6,
        'Servicio_Online_Backup': 7,
        'Servicio_Device_Protection': 7,
        'Servicio_Streaming_TV': 6,
        'Servicio_Streaming_Movies': 6,
        'Telefono_Multiples_Lineas': 7,
        'Edad': 1,
        'Senior_Citizen': 1,
        'Genero': 1
    }
    
    # Si la variable no est√° en el diccionario, asignar basado en patr√≥n
    if variable not in intervention_scores:
        # Logging para debug
        logging.info(f"Variable no mapeada: '{variable}' - asignando score por patr√≥n")
        
        variable_lower = variable.lower()
        
        if any(pattern in variable_lower for pattern in ['contrato', 'contract']):
            return 9  # Podemos intervenir f√°cilmente
        elif any(pattern in variable_lower for pattern in ['cargo', 'precio', 'monthly', 'charges']):
            if 'total' in variable_lower:
                return 2  # No podemos intervenir - hist√≥rico
            else:
                return 8  # Podemos intervenir f√°cilmente
        elif any(pattern in variable_lower for pattern in ['soporte', 'support', 'tecnico']):
            return 9  # Podemos intervenir f√°cilmente
        elif any(pattern in variable_lower for pattern in ['seguridad', 'security', 'online']):
            return 8  # Podemos intervenir f√°cilmente
        elif any(pattern in variable_lower for pattern in ['servicio', 'service']):
            return 6  # Podemos intervenir con esfuerzo
        elif any(pattern in variable_lower for pattern in ['metodo', 'pago', 'payment']):
            return 8  # Podemos intervenir f√°cilmente
        elif any(pattern in variable_lower for pattern in ['meses', 'months', 'tenure', 'cliente']):
            return 3  # No podemos intervenir mucho
        elif any(pattern in variable_lower for pattern in ['edad', 'age', 'genero', 'gender', 'senior']):
            return 1  # No podemos intervenir
        else:
            return 5  # Default medio
    
    return intervention_scores[variable]

def get_action_recommendation(importance, intervention_score):
    """Generar recomendaci√≥n de acci√≥n basada en importancia e intervenci√≥n"""
    
    if intervention_score >= 7:
        if importance >= 10:
            return "üöÄ ACCI√ìN INMEDIATA", "Alta prioridad - podemos intervenir f√°cilmente"
        else:
            return "‚úÖ PLANIFICAR", "Buena oportunidad - podemos intervenir f√°cilmente"
    elif intervention_score >= 4:
        if importance >= 10:
            return "‚è≥ PROYECTO COMPLEJO", "Importante pero requiere esfuerzo significativo"
        else:
            return "üîß CONSIDERAR", "Podemos intervenir con esfuerzo moderado"
    else:
        if importance >= 10:
            return "üìä MONITOREAR", "Importante pero no podemos intervenir directamente"
        else:
            return "‚ÑπÔ∏è INFORMATIVO", "Variable de contexto - sin acci√≥n directa"

def get_implementation_complexity(variable):
    """Evaluar complejidad de implementaci√≥n (Baja/Media/Alta)"""
    
    complexity_map = {
        # Baja complejidad
        'Metodo_Pago': 'Baja',
        'Facturacion_Digital': 'Baja',
        'Servicio_Online_Security': 'Baja',
        'Servicio_Tech_Support': 'Baja',
        
        # Media complejidad
        'Tipo_Contrato': 'Media',
        'Cargos_Mensuales': 'Media',
        
        # Alta complejidad
        'Servicio_Internet': 'Alta',    # Requiere infraestructura
        'Meses_Antig√ºedad': 'Alta',     # Requiere cambio de procesos
        
        # No aplicable
        'Edad': 'N/A',
        'Senior_Citizen': 'N/A',
        'Genero': 'N/A'
    }
    
    return complexity_map.get(variable, 'Media')

def get_time_to_impact(variable):
    """Estimar tiempo hasta ver impacto (en meses)"""
    
    time_to_impact = {
        # Impacto inmediato (1-3 meses)
        'Servicio_Tech_Support': 2,
        'Servicio_Online_Security': 2,
        'Metodo_Pago': 1,
        
        # Impacto medio (3-6 meses)
        'Tipo_Contrato': 4,
        'Facturacion_Digital': 3,
        'Cargos_Mensuales': 4,
        
        # Impacto largo (6+ meses)
        'Servicio_Internet': 12,       # Infraestructura
        'Meses_Antig√ºedad': 8,         # Cambio de procesos
        
        # No aplicable
        'Edad': 999,
        'Senior_Citizen': 999,
        'Genero': 999
    }
    
    return time_to_impact.get(variable, 6)  # Default 6 meses

def analyze_by_business_categories(critical_factors):
    """Analizar factores cr√≠ticos por categor√≠as de negocio"""
    logging.info("Analizando por categor√≠as de negocio...")
    
    try:
        # Agrupar por categor√≠as
        category_analysis = {}
        
        for factor in critical_factors:
            category = factor['category']
            
            if category not in category_analysis:
                category_analysis[category] = {
                    'variables': [],
                    'total_importance': 0,
                    'avg_actionability': 0,
                    'avg_complexity': [],
                    'avg_time_to_impact': 0,
                    'factors_count': 0
                }
            
            category_analysis[category]['variables'].append(factor['variable'])
            category_analysis[category]['total_importance'] += factor['avg_importance']
            category_analysis[category]['avg_actionability'] += factor['actionability_score']
            category_analysis[category]['avg_complexity'].append(factor['implementation_complexity'])
            category_analysis[category]['avg_time_to_impact'] += factor['time_to_impact']
            category_analysis[category]['factors_count'] += 1
        
        # Calcular promedios y m√©tricas finales
        for category, data in category_analysis.items():
            count = data['factors_count']
            
            # Promedios
            data['avg_importance'] = data['total_importance'] / count
            data['avg_actionability'] = data['avg_actionability'] / count
            data['avg_time_to_impact'] = data['avg_time_to_impact'] / count
            
            # Complejidad predominante
            complexity_counts = {}
            for comp in data['avg_complexity']:
                complexity_counts[comp] = complexity_counts.get(comp, 0) + 1
            data['predominant_complexity'] = max(complexity_counts, key=complexity_counts.get)
            
            # Prioridad estrat√©gica MEJORADA (basada en importancia y accionabilidad)
            # Dar m√°s peso a la accionabilidad para diferenciar categor√≠as
            importance_score = data['avg_importance'] * 0.4  # Reducir peso de importancia
            actionability_score = data['avg_actionability'] * 6  # Aumentar peso de accionabilidad
            priority_score = importance_score + actionability_score
            data['strategic_priority'] = priority_score
            
            # Clasificaci√≥n de prioridad MEJORADA con thresholds m√°s diferenciados
            if priority_score >= 45:
                data['priority_level'] = 'CR√çTICA'
            elif priority_score >= 35:
                data['priority_level'] = 'ALTA'
            elif priority_score >= 25:
                data['priority_level'] = 'MEDIA'
            else:
                data['priority_level'] = 'BAJA'
        
        # Ordenar por prioridad estrat√©gica
        sorted_categories = sorted(category_analysis.items(), 
                                 key=lambda x: x[1]['strategic_priority'], 
                                 reverse=True)
        
        logging.info(f"Analizadas {len(category_analysis)} categor√≠as de negocio")
        return dict(sorted_categories)
        
    except Exception as e:
        logging.error(f"Error analizando categor√≠as: {str(e)}")
        raise

def generate_business_insights(critical_factors, category_analysis, previous_results):
    """Generar insights clave de negocio"""
    logging.info("Generando insights de negocio...")
    
    try:
        model_info = previous_results['paso11']
        dataset_info = previous_results['dataset']
        
        # Top insights
        top_factor = critical_factors[0]
        most_actionable = max(critical_factors, key=lambda x: x['actionability_score'])
        least_actionable = min(critical_factors, key=lambda x: x['actionability_score'])
        
        # Insights por categor√≠a
        priority_category = list(category_analysis.keys())[0]  # Primera en orden de prioridad
        
        insights = {
            'model_performance': {
                'best_model': model_info['best_model'],
                'model_score': model_info['model_score'],
                'production_ready': model_info['production_ready']
            },
            'dataset_summary': {
                'total_customers': dataset_info['size'],
                'baseline_churn_rate': dataset_info['churn_rate'],
                'features_analyzed': len(dataset_info['features'])
            },
            'critical_factors_summary': {
                'total_factors_identified': len(critical_factors),
                'top_factor': {
                    'variable': top_factor['variable'],
                    'importance': top_factor['avg_importance'],
                    'category': top_factor['category']
                },
                'most_actionable': {
                    'variable': most_actionable['variable'],
                    'actionability': most_actionable['actionability_score'],
                    'category': most_actionable['category']
                },
                'least_actionable': {
                    'variable': least_actionable['variable'],
                    'actionability': least_actionable['actionability_score'],
                    'category': least_actionable['category']
                }
            },
            'category_insights': {
                'priority_category': priority_category,
                'total_categories': len(category_analysis),
                'high_priority_categories': len([cat for cat, data in category_analysis.items() 
                                               if data['priority_level'] in ['CR√çTICA', 'ALTA']])
            },
            'actionability_distribution': {
                'highly_actionable': len([f for f in critical_factors if f['actionability_score'] >= 7]),
                'moderately_actionable': len([f for f in critical_factors if 4 <= f['actionability_score'] < 7]),
                'low_actionable': len([f for f in critical_factors if f['actionability_score'] < 4])
            },
            'implementation_timeline': {
                'quick_wins': len([f for f in critical_factors if f['time_to_impact'] <= 3]),
                'medium_term': len([f for f in critical_factors if 3 < f['time_to_impact'] <= 6]),
                'long_term': len([f for f in critical_factors if f['time_to_impact'] > 6])
            }
        }
        
        return insights
        
    except Exception as e:
        logging.error(f"Error generando insights: {str(e)}")
        raise

def create_visualization(critical_factors, category_analysis, timestamp):
    """Crear visualizaci√≥n mejorada de factores cr√≠ticos"""
    logging.info("Creando visualizaci√≥n mejorada de an√°lisis consolidado...")
    
    try:
        # Configurar el gr√°fico con 3 subplots
        plt.style.use('default')  # Resetear estilo
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))
        plt.subplots_adjust(hspace=0.25, wspace=0.25, top=0.85, bottom=0.15, left=0.05, right=0.95)
        
        # 1. Top 8 factores cr√≠ticos - COLORES ESPEC√çFICOS POR RANGO
        top_8_factors = critical_factors[:8]
        variables = [f['variable'].replace('_', ' ')[:20] for f in top_8_factors]
        importances = [f['avg_importance'] for f in top_8_factors]
        
        # NUEVA L√ìGICA: Colores espec√≠ficos por rangos de importancia
        colors = []
        for imp in importances:
            if imp >= 15.0:  # 20% a 15%
                colors.append('#F4320B')  # Rojo intenso
            elif imp >= 6.0:  # 14.9% a 6%
                colors.append('#F54927')  # Rojo medio
            else:  # Por debajo de 6%
                colors.append('#F87C63')  # Rojo claro
        
        # Debug: mostrar clasificaci√≥n por rangos
        logging.info("Clasificaci√≥n por rangos de importancia:")
        for var, imp, color in zip([f['variable'] for f in top_8_factors], importances, colors):
            if imp >= 15.0:
                category = "CR√çTICO (‚â•15%)"
            elif imp >= 6.0:
                category = "IMPORTANTE (6-14.9%)"
            else:
                category = "MODERADO (<6%)"
            logging.info(f"  {var}: {imp:.1f}% -> {color} ({category})")
        
        bars = ax1.barh(range(len(variables)), importances, color=colors, alpha=0.9, 
                       edgecolor='black', linewidth=0.8)
        ax1.set_yticks(range(len(variables)))
        ax1.set_yticklabels(variables, fontsize=11, fontweight='bold')
        ax1.set_xlabel('Importancia Promedio (%)', fontsize=12, fontweight='bold')
        ax1.set_title('Top 8 Factores Cr√≠ticos de Churn\n(Rojo Intenso: ‚â•15%, Rojo Medio: 6-14.9%, Rojo Claro: <6%)', 
                     fontweight='bold', fontsize=12, pad=20)
        ax1.invert_yaxis()
        
        # A√±adir valores de importancia
        for i, (bar, imp) in enumerate(zip(bars, importances)):
            ax1.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, 
                    f'{imp:.1f}%', va='center', ha='left', 
                    fontsize=11, fontweight='bold', color='black')
        
        ax1.grid(True, alpha=0.3, axis='x')
        ax1.set_xlim(0, max(importances) * 1.3)
        
        # 2. An√°lisis por categor√≠as - MANTENEMOS IGUAL
        categories = list(category_analysis.keys())[:5]
        cat_priorities = [category_analysis[cat]['strategic_priority'] for cat in categories]
        
        # Colores por nivel de prioridad
        priority_colors = {
            'CR√çTICA': '#B22222',  # Rojo oscuro
            'ALTA': '#FF6347',     # Rojo-naranja 
            'MEDIA': '#FFD700',    # Amarillo
            'BAJA': '#90EE90'      # Verde claro
        }
        
        cat_colors = []
        for cat in categories:
            level = category_analysis[cat]['priority_level']
            color = priority_colors.get(level, '#87CEEB')
            cat_colors.append(color)
        
        cat_names = [cat.replace('_', '\n').replace('Servicios', 'Serv') for cat in categories]
        
        bars2 = ax2.bar(range(len(categories)), cat_priorities, color=cat_colors, alpha=0.8, 
                       edgecolor='black', linewidth=0.8)
        ax2.set_xticks(range(len(categories)))
        ax2.set_xticklabels(cat_names, fontsize=11, fontweight='bold', ha='center')
        ax2.set_ylabel('Score de Prioridad Estrat√©gica', fontsize=12, fontweight='bold')
        ax2.set_title('Prioridad Estrat√©gica por Categor√≠a\n(Rojo: Cr√≠tica, Naranja: Alta, Amarillo: Media)', 
                     fontweight='bold', fontsize=12, pad=20)
        
        for bar, priority in zip(bars2, cat_priorities):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.8,
                    f'{priority:.1f}', ha='center', va='bottom', 
                    fontweight='bold', fontsize=11, color='black')
        
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.set_ylim(0, max(cat_priorities) * 1.3)
        
        # 3. Timeline de implementaci√≥n - MANTENEMOS IGUAL
        timeline_labels = ['Quick Wins\n(1-3 meses)', 'Medio Plazo\n(3-6 meses)', 'Largo Plazo\n(6+ meses)']
        timeline_counts = [
            len([f for f in critical_factors if f['time_to_impact'] <= 3]),
            len([f for f in critical_factors if 3 < f['time_to_impact'] <= 6]),
            len([f for f in critical_factors if f['time_to_impact'] > 6])
        ]
        
        colors_timeline = ['#40E0D0', '#87CEEB', '#4682B4']
        bars3 = ax3.bar(timeline_labels, timeline_counts, color=colors_timeline, alpha=0.8,
                       edgecolor='black', linewidth=0.8)
        ax3.set_ylabel('N√∫mero de Factores', fontsize=12, fontweight='bold')
        ax3.set_title('Timeline de Implementaci√≥n\npor Factor Cr√≠tico', 
                     fontweight='bold', fontsize=12, pad=20)
        
        for bar, count in zip(bars3, timeline_counts):
            if count > 0:
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,
                        str(count), ha='center', va='bottom', 
                        fontweight='bold', fontsize=11, color='black')
        
        ax3.grid(True, alpha=0.3, axis='y')
        ax3.set_ylim(0, max(timeline_counts) * 1.4 if timeline_counts else 1)
        
        # T√≠tulo principal
        fig.suptitle('TelecomX - An√°lisis Consolidado de Factores Cr√≠ticos de Churn', 
                    fontsize=18, fontweight='bold', y=0.95)
        
        # Guardar visualizaci√≥n
        viz_file = f'graficos/paso13a_analisis_consolidado_v2_{timestamp}.png'
        plt.savefig(viz_file, dpi=300, bbox_inches='tight', facecolor='white', 
                   edgecolor='none', pad_inches=0.3)
        plt.close()
        
        logging.info(f"Visualizaci√≥n con colores espec√≠ficos guardada: {viz_file}")
        return viz_file
        
    except Exception as e:
        logging.error(f"Error creando visualizaci√≥n: {str(e)}")
        return None

def generate_summary_report(consolidated_data):
    """Generar informe resumen del an√°lisis consolidado"""
    
    critical_factors = consolidated_data['critical_factors']
    category_analysis = consolidated_data['category_analysis']
    insights = consolidated_data['business_insights']
    timestamp = consolidated_data['metadata']['timestamp']
    
    report = f"""
================================================================================
TELECOMX - PASO 13A: AN√ÅLISIS CONSOLIDADO - RESUMEN EJECUTIVO (V2)
================================================================================
Fecha: {timestamp}
Script: {consolidated_data['metadata']['script']}

================================================================================
RESUMEN DE HALLAZGOS PRINCIPALES
================================================================================

üéØ MODELO PREDICTIVO VALIDADO:
‚Ä¢ Mejor modelo: {insights['model_performance']['best_model']}
‚Ä¢ Score de performance: {insights['model_performance']['model_score']:.4f}
‚Ä¢ Estado para producci√≥n: {'‚úÖ LISTO' if insights['model_performance']['production_ready'] else '‚ùå NO LISTO'}

üìä DATASET ANALIZADO:
‚Ä¢ Total de clientes: {insights['dataset_summary']['total_customers']:,}
‚Ä¢ Tasa de churn baseline: {insights['dataset_summary']['baseline_churn_rate']:.1%}
‚Ä¢ Variables analizadas: {insights['dataset_summary']['features_analyzed']}

================================================================================
FACTORES CR√çTICOS IDENTIFICADOS
================================================================================

üî• TOP 5 FACTORES M√ÅS CR√çTICOS:
"""
    
    # Top 5 factores
    for i, factor in enumerate(critical_factors[:5], 1):
        actionability_icon = "üü¢" if factor['actionability_score'] >= 7 else "üü°" if factor['actionability_score'] >= 5 else "üî¥"
        
        report += f"""
{i}. {factor['variable'].upper()}:
   üìà Importancia: {factor['avg_importance']:.2f}%
   ‚ö° Accionabilidad: {actionability_icon} {factor['actionability_score']}/10
   üè¢ Categor√≠a: {factor['category']}
   ‚è±Ô∏è Tiempo impacto: {factor['time_to_impact']} meses
   üìã Complejidad: {factor['implementation_complexity']}
   üí° Insight: {factor['business_impact'][:100]}...
"""

    report += f"""

üéØ VARIABLE M√ÅS IMPORTANTE:
‚Ä¢ {insights['critical_factors_summary']['top_factor']['variable']}: {insights['critical_factors_summary']['top_factor']['importance']:.2f}%
‚Ä¢ Categor√≠a: {insights['critical_factors_summary']['top_factor']['category']}

‚ö° VARIABLE M√ÅS ACCIONABLE:
‚Ä¢ {insights['critical_factors_summary']['most_actionable']['variable']}: {insights['critical_factors_summary']['most_actionable']['actionability']}/10
‚Ä¢ Categor√≠a: {insights['critical_factors_summary']['most_actionable']['category']}

================================================================================
AN√ÅLISIS POR CATEGOR√çAS DE NEGOCIO
================================================================================

üèÜ RANKING DE CATEGOR√çAS POR PRIORIDAD ESTRAT√âGICA:
"""
    
    # Ranking de categor√≠as
    for i, (category, data) in enumerate(list(category_analysis.items())[:5], 1):
        priority_icon = "üî¥" if data['priority_level'] == 'CR√çTICA' else "üü°" if data['priority_level'] == 'ALTA' else "üü¢"
        
        report += f"""
{i}. {category.replace('_', ' ').upper()}:
   üéØ Prioridad: {priority_icon} {data['priority_level']}
   üìä Score estrat√©gico: {data['strategic_priority']:.1f}
   üìà Importancia promedio: {data['avg_importance']:.1f}%
   ‚ö° Accionabilidad promedio: {data['avg_actionability']:.1f}/10
   ‚è±Ô∏è Tiempo promedio impacto: {data['avg_time_to_impact']:.1f} meses
   üîß Complejidad predominante: {data['predominant_complexity']}
   üìù Variables: {', '.join(data['variables'])}
"""

    report += f"""

================================================================================
DISTRIBUCI√ìN DE ACCIONABILIDAD
================================================================================

‚ö° NIVELES DE ACCIONABILIDAD:
‚Ä¢ üü¢ ALTA (7-10): {insights['actionability_distribution']['highly_actionable']} factores
‚Ä¢ üü° MEDIA (4-6): {insights['actionability_distribution']['moderately_actionable']} factores  
‚Ä¢ üî¥ BAJA (1-3): {insights['actionability_distribution']['low_actionable']} factores

‚è±Ô∏è TIMELINE DE IMPLEMENTACI√ìN:
‚Ä¢ üöÄ Quick Wins (1-3 meses): {insights['implementation_timeline']['quick_wins']} factores
‚Ä¢ üìÖ Medio Plazo (3-6 meses): {insights['implementation_timeline']['medium_term']} factores
‚Ä¢ üìÜ Largo Plazo (6+ meses): {insights['implementation_timeline']['long_term']} factores

================================================================================
INSIGHTS CLAVE PARA ESTRATEGIA
================================================================================

üí° HALLAZGOS PRINCIPALES:

1. CONCENTRACI√ìN DE OPORTUNIDADES:
   ‚Ä¢ {insights['category_insights']['high_priority_categories']} de {insights['category_insights']['total_categories']} categor√≠as son de prioridad ALTA/CR√çTICA
   ‚Ä¢ Categor√≠a prioritaria: {insights['category_insights']['priority_category']}
   ‚Ä¢ {insights['actionability_distribution']['highly_actionable']} factores son altamente accionables

2. OPORTUNIDADES DE QUICK WINS:
   ‚Ä¢ {insights['implementation_timeline']['quick_wins']} factores pueden generar impacto en 1-3 meses
   ‚Ä¢ Variables m√°s accionables est√°n en categor√≠as: {', '.join([cat for cat, data in list(category_analysis.items())[:3] if data['avg_actionability'] >= 6])}

3. BALANCE IMPACTO-ESFUERZO:
   ‚Ä¢ Factor con mejor ratio impacto/accionabilidad: {insights['critical_factors_summary']['most_actionable']['variable']}
   ‚Ä¢ Categor√≠as que requieren menos inversi√≥n pero generan alto impacto identificadas

================================================================================
RECOMENDACIONES INMEDIATAS
================================================================================

üöÄ ACCIONES PRIORITARIAS:

1. IMPLEMENTACI√ìN INMEDIATA (1-3 meses):
   ‚Ä¢ Focus en factores con accionabilidad ‚â•7 y tiempo impacto ‚â§3 meses
   ‚Ä¢ Priorizar categor√≠a: {insights['category_insights']['priority_category']}
   ‚Ä¢ Variables clave: {', '.join([f['variable'] for f in critical_factors if f['actionability_score'] >= 7 and f['time_to_impact'] <= 3][:3])}

2. PLANIFICACI√ìN MEDIO PLAZO (3-6 meses):
   ‚Ä¢ Preparar implementaci√≥n de factores con complejidad media
   ‚Ä¢ Desarrollar capacidades para categor√≠as de alta prioridad
   ‚Ä¢ Investment en infraestructura para factores de largo impacto

3. PREPARACI√ìN ESTRAT√âGICA:
   ‚Ä¢ Alinear recursos con categor√≠as de mayor prioridad estrat√©gica
   ‚Ä¢ Desarrollar m√©tricas de seguimiento espec√≠ficas por factor
   ‚Ä¢ Establecer governance para implementaci√≥n por fases

================================================================================
PR√ìXIMOS PASOS
================================================================================

üìã SIGUIENTES SCRIPTS DEL PASO 13:

1. paso13b_conclusion_Segmentaci√≥n_Estrat√©gica.py:
   ‚Ä¢ Utilizar√° estos factores cr√≠ticos para definir segmentos
   ‚Ä¢ Crear√° estrategias espec√≠ficas por tipo de cliente
   ‚Ä¢ Input principal: factores con alta accionabilidad

2. paso13c_conclusion_Business_Case_Completo.py:
   ‚Ä¢ Calcular√° ROI espec√≠fico por factor y categor√≠a
   ‚Ä¢ Estimar√° impacto financiero de intervenciones
   ‚Ä¢ Priorizar√° inversiones basado en estos hallazgos

3. paso13d_conclusion_Roadmap_Detallado.py:
   ‚Ä¢ Utilizar√° timeline de implementaci√≥n identificado
   ‚Ä¢ Crear√° cronograma basado en complejidad y dependencias
   ‚Ä¢ Organizar√° por quick wins vs proyectos de largo plazo

üìä ARCHIVOS GENERADOS:
‚Ä¢ Datos consolidados JSON: datos/paso13a_analisis_consolidado_v2_{timestamp}.json
‚Ä¢ Visualizaci√≥n mejorada: {consolidated_data['visualization_file'] if consolidated_data['visualization_file'] else 'No generada'}
‚Ä¢ Este informe: informes/paso13a_analisis_consolidado_resumen_v2_{timestamp}.txt

================================================================================
CONCLUSI√ìN
================================================================================

‚úÖ AN√ÅLISIS CONSOLIDADO COMPLETADO EXITOSAMENTE:

‚Ä¢ {len(critical_factors)} factores cr√≠ticos identificados y categorizados
‚Ä¢ {len(category_analysis)} categor√≠as de negocio priorizadas estrat√©gicamente
‚Ä¢ {insights['actionability_distribution']['highly_actionable']} factores altamente accionables disponibles para implementaci√≥n inmediata
‚Ä¢ Base s√≥lida establecida para segmentaci√≥n estrat√©gica y business case

üéØ FACTOR M√ÅS CR√çTICO: {insights['critical_factors_summary']['top_factor']['variable']}
‚ö° FACTOR M√ÅS ACCIONABLE: {insights['critical_factors_summary']['most_actionable']['variable']}
üèÜ CATEGOR√çA PRIORITARIA: {insights['category_insights']['priority_category']}

La base anal√≠tica est√° lista para desarrollar estrategias espec√≠ficas de retenci√≥n
con alto potencial de ROI y implementaci√≥n efectiva.

================================================================================
FIN DEL RESUMEN
================================================================================
"""
    
    return report

def save_consolidated_results(critical_factors, category_analysis, business_insights, previous_results, viz_file, timestamp):
    """Guardar resultados consolidados para scripts posteriores"""
    try:
        # Crear estructura de datos consolidados
        consolidated_data = {
            'metadata': {
                'timestamp': timestamp,
                'script': 'paso13a_conclusion_An√°lisis_Consolidado_v2',
                'version': '2.0',
                'total_factors': len(critical_factors),
                'total_categories': len(category_analysis)
            },
            'model_info': previous_results['paso11'],
            'dataset_info': {
                'size': previous_results['dataset']['size'],
                'churn_rate': previous_results['dataset']['churn_rate'],
                'features_count': len(previous_results['dataset']['features'])
            },
            'critical_factors': critical_factors,
            'category_analysis': category_analysis,
            'business_insights': business_insights,
            'visualization_file': viz_file
        }
        
        # Guardar JSON para scripts posteriores
        json_file = f'datos/paso13a_analisis_consolidado_v2_{timestamp}.json'
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(consolidated_data, f, indent=2, ensure_ascii=False, default=str)
        
        # Guardar informe resumido
        report_content = generate_summary_report(consolidated_data)
        report_file = f'informes/paso13a_analisis_consolidado_resumen_v2_{timestamp}.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"Datos consolidados guardados: {json_file}")
        logging.info(f"Informe resumen guardado: {report_file}")
        
        return {
            'json_file': json_file,
            'report_file': report_file,
            'data': consolidated_data
        }
        
    except Exception as e:
        logging.error(f"Error guardando resultados: {str(e)}")
        raise

def main():
    """Funci√≥n principal del Paso 13A - Versi√≥n 2"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    logger = setup_logging()
    
    try:
        logger.info("="*80)
        logger.info("INICIANDO PASO 13A: AN√ÅLISIS CONSOLIDADO DE FACTORES DE CHURN - V2")
        logger.info("="*80)
        logger.info("Versi√≥n mejorada con visualizaciones optimizadas")
        
        # 1. Crear directorios necesarios
        create_directories()
        
        # 2. Cargar resultados de pasos anteriores
        logger.info("="*50)
        logger.info("CARGANDO RESULTADOS DE PASOS ANTERIORES")
        previous_results = load_previous_results()
        
        # 3. Identificar factores cr√≠ticos de churn
        logger.info("="*50)
        logger.info("IDENTIFICANDO FACTORES CR√çTICOS DE CHURN")
        critical_factors = identify_critical_churn_factors(previous_results)
        
        # 4. Analizar por categor√≠as de negocio
        logger.info("="*50)
        logger.info("ANALIZANDO POR CATEGOR√çAS DE NEGOCIO")
        category_analysis = analyze_by_business_categories(critical_factors)
        
        # 5. Generar insights de negocio
        logger.info("="*50)
        logger.info("GENERANDO INSIGHTS DE NEGOCIO")
        business_insights = generate_business_insights(critical_factors, category_analysis, previous_results)
        
        # 6. Crear visualizaci√≥n mejorada
        logger.info("="*50)
        logger.info("GENERANDO VISUALIZACI√ìN MEJORADA")
        viz_file = create_visualization(critical_factors, category_analysis, timestamp)
        
        # 7. Guardar resultados consolidados
        logger.info("="*50)
        logger.info("GUARDANDO RESULTADOS CONSOLIDADOS")
        output_files = save_consolidated_results(critical_factors, category_analysis, 
                                               business_insights, previous_results, viz_file, timestamp)
        
        # 8. Resumen final
        logger.info("="*80)
        logger.info("PASO 13A V2 COMPLETADO EXITOSAMENTE")
        logger.info("="*80)
        logger.info("")
        
        # Mostrar hallazgos principales
        logger.info("üéØ FACTORES CR√çTICOS IDENTIFICADOS:")
        for i, factor in enumerate(critical_factors[:5], 1):
            actionability = "üü¢ Alta" if factor['actionability_score'] >= 7 else "üü° Media" if factor['actionability_score'] >= 5 else "üî¥ Baja"
            logger.info(f"  {i}. {factor['variable']}: {factor['avg_importance']:.1f}% | {actionability}")
        logger.info("")
        
        logger.info("üè¢ CATEGOR√çAS PRIORITARIAS:")
        for i, (category, data) in enumerate(list(category_analysis.items())[:3], 1):
            logger.info(f"  {i}. {category.replace('_', ' ')}: {data['priority_level']} ({data['strategic_priority']:.1f} pts)")
        logger.info("")
        
        logger.info("‚ö° DISTRIBUCI√ìN DE ACCIONABILIDAD:")
        logger.info(f"  ‚Ä¢ Alta (7-10): {business_insights['actionability_distribution']['highly_actionable']} factores")
        logger.info(f"  ‚Ä¢ Media (4-6): {business_insights['actionability_distribution']['moderately_actionable']} factores")
        logger.info(f"  ‚Ä¢ Baja (1-3): {business_insights['actionability_distribution']['low_actionable']} factores")
        logger.info("")
        
        logger.info("üìÅ ARCHIVOS GENERADOS:")
        logger.info(f"  ‚Ä¢ Datos consolidados: {output_files['json_file']}")
        logger.info(f"  ‚Ä¢ Informe resumen: {output_files['report_file']}")
        if viz_file:
            logger.info(f"  ‚Ä¢ Visualizaci√≥n mejorada: {viz_file}")
        logger.info("")
        
        logger.info("‚úÖ MEJORAS IMPLEMENTADAS EN V2:")
        logger.info("  ‚Ä¢ Visualizaciones con colores profesionales")
        logger.info("  ‚Ä¢ Mejor espaciado y legibilidad")
        logger.info("  ‚Ä¢ Texto sin superposici√≥n")
        logger.info("  ‚Ä¢ Gr√°ficos de mayor resoluci√≥n")
        logger.info("")
        
        logger.info("üìã LISTO PARA PR√ìXIMOS SCRIPTS:")
        logger.info("  ‚Ä¢ paso13b: Segmentaci√≥n estrat√©gica")
        logger.info("  ‚Ä¢ paso13c: Business case con ROI")
        logger.info("  ‚Ä¢ paso13d: Roadmap de implementaci√≥n")
        logger.info("="*80)
        
        return output_files['data']
        
    except Exception as e:
        logger.error(f"ERROR EN EL PROCESO: {str(e)}")
        import traceback
        logger.error(f"Traceback completo: {traceback.format_exc()}")
        raise

if __name__ == "__main__":
    main()